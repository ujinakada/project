# General settings.
spk: "jsut"

# exp tag(for managing experiments)
tag:

sample_rate: 16000

# 1) none 2) tqdm
# NOTE: Jupyterノートブックからrun.shを実行する場合は、none推奨
tqdm: tqdm

# Mu-law quantization parameter
mu: 255

# NOTE: benchmarkをtrueにすると、高速化が期待できる分、より多くの
# GPUリソースを必要とする場合があります。
# GPUリソースに余裕がある場合は、true にしてください。
cudnn_benchmark: false
cudnn_deterministic: false

###########################################################
#                DATA PREPARATION SETTING                 #
###########################################################

# PLEASE CHANGE THE PATH BASED ON YOUR ENVIRONMENT
wav_root: "data/mono"
lab_root: "data/label"

n_jobs: 4

###########################################################
#                FEATURE EXTRACTION SETTING               #
###########################################################

###########################################################
#                TRAINING SETTING                         #
###########################################################

acoustic_model: tacotron2_rf2
wavenet_model: wavenet_sr16k_mulaw256_30layers

### Tacotron  ###
# エポック数を小さくすると、学習は早く終了します。
tacotron_train_max_train_steps: 50000
# バッチサイズを小さくすると、GPUメモリ使用量が小さく済みます。
# 注意: 必要なGPUメモリ（目安）:
# バッチサイズ16の場合に6GB程度、バッチサイズ32の場合に12GB程度
# 必要なGPUメモリはミニバッチ内の発話の最大系列長に依存するため、
# 余裕を持ってより多くのGPUメモリを確保しておくことを推奨します
tacotron_data_batch_size: 128

### WaveNet ###
# 注意: 50万ステップの学習には数日時間がかかることが予想されます
wavenet_train_max_train_steps: 400000
# 注意: 必要なGPUメモリ（目安）:
# バッチサイズ8の場合に10GB程度、バッチサイズ16の場合に17GB程度
# PyTorch 1.8.1, CUDA 11.2, cuDNN 7.6.3
wavenet_data_batch_size: 64

###########################################################
#                SYNTHESIS SETTING                        #
###########################################################

# リストの逆順で発話を処理する
reverse: false

# 生成する発話の数
# -1 の場合、評価の発話をすべて処理する
# 音声生成にかかる時間を短縮する場合、小さな値（5など）に設定してください
num_eval_utts: -1

acoustic_eval_checkpoint: epoch0200.pth
wavenet_eval_checkpoint: latest_ema.pth
